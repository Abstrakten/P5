\section{Tracking}\label{predesign:tracking}
Tracking can be divided into two parts: determining position and reacting to movement.

\subsection{Determining Position}\label{deterpositon}
Determining the position of a target is a problem which is closely related to detection of a target. The problem of determining a position is a matter of interpreting information acquired from detection, and trying to infer a position based on this. In the case of image recognition it might be as straight forward as measuring the offset from the detected target to a known point. \\

When it comes to motion detection, the ability to figure out the position of a detected target can vary a great deal, based on the properties of the sensors. Two variables are to primarily be considered. One is the field of view of the sensors, and the other is the precision of the information regarding the position within the observed area. For example, imagine a sensor with a field of view matching the observable area, which can only give the information \emph{detected} or \emph{not detected}. In this scenario, pinpointing a position is only possible if the velocity of the target is known, which can not be assumed. But imagining a very narrow field of view, it suddenly becomes possible to estimate the position, by moving the field of view through the observable area and taking note of the position where a measurement is taken. The best case scenario, however, is a sensor with field of view matching the observable area, which is also able to give precise information about the position of the detected object, in which case the process becomes trivial \cite{1219468}. \\

If the information acquired from a single sensor is limited, using multiple sensors can increase the amount of information gathered. When using multiple sensors, it is possible, depending on the properties of the sensors, to arrange them in certain pattern which provide synergy. One such example is to let simple \emph{detected / not detected} fields of view intersect. Such a setup will increase the information from three possible areas, sensor A detects it, sensor B detects it, and neither detect it, to four areas with the last being the intersection: Both sensor A and B detect it. \\

\subsection{Reacting to Movement}
Reacting to movement can be modelled as a two step process consisting of prediction and evaluation \cite{1219468}. The prediction step is the process of analyzing information about the target, and trying to predict its future state. The evaluation step is the process of evaluating a prediction, adding further information for the prediction step. The importance of the two processes varies based on different factors. If the information gathered through the sensors is considered accurate and plentiful, then the evaluation step will be a less important source of information. But in cases with little or inaccurate information, the evaluation step can be of great importance, especially if the sensors are not covering the entire observable area, and are directed based on the prediction step. An example of this is the first measurement where a target is detected. At that point in time the prediction step can not know the speed of the target, and the prediction is likely to be wrong. In this case, it will often prove useful to evaluate the first prediction. \\

Unlike the evaluation step, the prediction step can not be marginalized. The problem with the prediction step is instead a problem of information dependence. It is obvious that a correct prediction will depend on some information, but the amount of information required for a correct prediction should be considered the benchmark for any tracking system. The definition of \enquote{correct prediction} can vary, but in this project a correct prediction is considered to be on both position and velocity of the target, since these will be required for meeting all of the requirements. It is also important to note, that although correct predictions are always a priority, sometimes it can prove useful to initially focus on being in proximity of the target, such as with the narrow fielded but movable sensors.

\section{Trajectory Prediction}\label{predesign:shoot}
The last part of the preliminary design will consider trajectory prediction. The actual processes of aiming and shooting will not be covered in the preliminary design since they are trivial when hardware factors are not considered. Trajectory prediction does, however, deserve a mentioning. Given that the predictions on positions and velocity are correct, the right trajectory can be calculated with information on projectile speed and launch delays. But remembering that this process involves mechanical movement which is prone to inaccuracies, at least from a mathematical standpoint, a margin of error is expected. This error margin includes the angle of the target relative to the tower, the width of the target, and whether the tracked point of the target is closer to the front of the target or the rear.\\

